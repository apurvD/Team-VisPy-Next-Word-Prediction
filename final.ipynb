{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pickle import load\nfrom keras.models import load_model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:18.076010Z","iopub.execute_input":"2023-02-20T14:37:18.076920Z","iopub.status.idle":"2023-02-20T14:37:21.301734Z","shell.execute_reply.started":"2023-02-20T14:37:18.076834Z","shell.execute_reply":"2023-02-20T14:37:21.300153Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1 = load_model(r'/kaggle/input/modelfiles/model_5.h5')\ntokenizer_1 = load(open(r'/kaggle/input/modelfiles/tokenizer_5.pkl', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:21.309557Z","iopub.execute_input":"2023-02-20T14:37:21.310107Z","iopub.status.idle":"2023-02-20T14:37:22.098991Z","shell.execute_reply.started":"2023-02-20T14:37:21.310061Z","shell.execute_reply":"2023-02-20T14:37:22.097824Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2023-02-20 14:37:21.325692: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n2023-02-20 14:37:21.325768: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}]},{"cell_type":"code","source":"seed_text = 'data'\nres = len(seed_text.split())\nif(res>5):\n    res=3\n    seed_text = seed_text.split()\n    lent = len(seed_text)\n    lent = lent-3\n    seed_text = seed_text[lent:]\n    seed_text = ' '.join(map(str, seed_text))\n\n\nseq_length = res\n\n\n\nif(res==1):\n    model=model_1\n    tokenizer = tokenizer_1\nelif(res==2):\n    #For 2nd prediction\n    model_new = model_1\n    tokenizer_new = tokenizer_1\n    #For 1st prediction\n    model=model_2\n    tokenizer = tokenizer_2\n     ","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:26.769123Z","iopub.execute_input":"2023-02-20T14:37:26.769547Z","iopub.status.idle":"2023-02-20T14:37:26.779096Z","shell.execute_reply.started":"2023-02-20T14:37:26.769514Z","shell.execute_reply":"2023-02-20T14:37:26.776999Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"final = input(\"Enter your text :\")\n","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:38:05.680695Z","iopub.execute_input":"2023-02-20T14:38:05.681227Z","iopub.status.idle":"2023-02-20T14:38:10.875223Z","shell.execute_reply.started":"2023-02-20T14:38:05.681185Z","shell.execute_reply":"2023-02-20T14:38:10.873601Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your text : Samuel is the \n"}]},{"cell_type":"code","source":"next_words = 4","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:38.729598Z","iopub.execute_input":"2023-02-20T14:37:38.730163Z","iopub.status.idle":"2023-02-20T14:37:38.735974Z","shell.execute_reply.started":"2023-02-20T14:37:38.730119Z","shell.execute_reply":"2023-02-20T14:37:38.734353Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"res = len(seed_text.split())\nseq_length = res\n\n\nif(res==1):\n    model=model_1\n    tokenizer = tokenizer_1\nelif(res==2):\n    #For 2nd prediction\n    model_new = model_1\n    tokenizer_new = tokenizer_1\n    #For 1st prediction\n    model=model_1\n    tokenizer = tokenizer_1","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:37:39.852394Z","iopub.execute_input":"2023-02-20T14:37:39.852833Z","iopub.status.idle":"2023-02-20T14:37:39.860425Z","shell.execute_reply.started":"2023-02-20T14:37:39.852795Z","shell.execute_reply":"2023-02-20T14:37:39.859045Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for _ in range(next_words):\n    token_list = tokenizer.texts_to_sequences([final])[0]\n    token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n    predicted=model.predict(token_list) \n    predicted=np.argmax(predicted,axis=1)\n    output_word = \"\"\n    for word, index in tokenizer.word_index.items():\n        if index == predicted:\n            output_word = word\n            break\n    final += \" \" + output_word\nprint(final)","metadata":{"execution":{"iopub.status.busy":"2023-02-20T14:38:13.208985Z","iopub.execute_input":"2023-02-20T14:38:13.210748Z","iopub.status.idle":"2023-02-20T14:38:13.490195Z","shell.execute_reply.started":"2023-02-20T14:38:13.210684Z","shell.execute_reply":"2023-02-20T14:38:13.488982Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\nSamuel is the  trap by howto case\n","output_type":"stream"}]}]}